Starting Epoch 1/15
Iteration 0 : loss : 5.302599
Iteration 1 : loss : 5.276190
Iteration 2 : loss : 5.250974
Iteration 3 : loss : 5.211352
Iteration 4 : loss : 5.211953
Iteration 5 : loss : 5.171093
Iteration 6 : loss : 5.137887
Iteration 7 : loss : 5.110597
Iteration 8 : loss : 5.042653
Iteration 9 : loss : 5.010025
Iteration 10 : loss : 4.975050
Iteration 11 : loss : 4.919867
Iteration 12 : loss : 4.841304
Iteration 13 : loss : 4.773017
Iteration 14 : loss : 4.765017
Iteration 15 : loss : 4.662794
Iteration 16 : loss : 4.605106
Iteration 17 : loss : 4.554559
Iteration 18 : loss : 4.513824
Iteration 19 : loss : 4.400209
Iteration 20 : loss : 4.398869
Iteration 21 : loss : 4.320618
Iteration 22 : loss : 4.181489
Iteration 23 : loss : 4.137485
Iteration 24 : loss : 4.231764
Iteration 25 : loss : 4.181405
Iteration 26 : loss : 4.049800
Iteration 27 : loss : 3.982100
Iteration 28 : loss : 3.889916
Iteration 29 : loss : 3.985659
Iteration 30 : loss : 3.947068
Iteration 31 : loss : 3.890229
Iteration 32 : loss : 3.974555
Finished Epoch 2/15,                       Train Accuracy: 0.18276572227478027,                       Train Loss: 4.618253735972381
--------------------------------------------------
Starting Epoch 2/15
Iteration 33 : loss : 3.572248
Iteration 34 : loss : 3.571922
Iteration 35 : loss : 3.513363
Iteration 36 : loss : 3.580316
Iteration 37 : loss : 3.481145
Iteration 38 : loss : 3.467662
Iteration 39 : loss : 3.557774
Iteration 40 : loss : 3.661864
Iteration 41 : loss : 3.460378
Iteration 42 : loss : 3.355161
Iteration 43 : loss : 3.429926
Iteration 44 : loss : 3.442594
Iteration 45 : loss : 3.453967
Iteration 46 : loss : 3.471105
Iteration 47 : loss : 3.482017
Iteration 48 : loss : 3.398444
Iteration 49 : loss : 3.359198
Iteration 50 : loss : 3.298783
Iteration 51 : loss : 3.315594
Iteration 52 : loss : 3.369889
Iteration 53 : loss : 3.354597
Iteration 54 : loss : 3.253157
Iteration 55 : loss : 3.262022
Iteration 56 : loss : 3.331373
Iteration 57 : loss : 3.282938
Iteration 58 : loss : 3.341454
Iteration 59 : loss : 3.303348
Iteration 60 : loss : 3.183671
Iteration 61 : loss : 3.338652
Iteration 62 : loss : 3.406263
Iteration 63 : loss : 3.231471
Iteration 64 : loss : 3.249161
Iteration 65 : loss : 3.255041
Finished Epoch 3/15,                       Train Accuracy: 0.4792146384716034,                       Train Loss: 3.398388082829985
--------------------------------------------------
Starting Epoch 3/15
Iteration 66 : loss : 3.018143
Iteration 67 : loss : 3.165394
Iteration 68 : loss : 3.056051
Iteration 69 : loss : 2.983750
Iteration 70 : loss : 3.139561
Iteration 71 : loss : 3.062222
Iteration 72 : loss : 3.080585
Iteration 73 : loss : 3.010252
Iteration 74 : loss : 3.035567
Iteration 75 : loss : 3.033740
Iteration 76 : loss : 3.054002
Iteration 77 : loss : 3.043051
Iteration 78 : loss : 2.982693
Iteration 79 : loss : 3.038434
Iteration 80 : loss : 3.007884
Iteration 81 : loss : 2.984482
Iteration 82 : loss : 3.065052
Iteration 83 : loss : 3.088316
Iteration 84 : loss : 2.954036
Iteration 85 : loss : 2.906330
Iteration 86 : loss : 3.008557
Iteration 87 : loss : 2.997614
Iteration 88 : loss : 3.038355
Iteration 89 : loss : 2.982584
Iteration 90 : loss : 2.995207
Iteration 91 : loss : 2.992936
Iteration 92 : loss : 2.953448
Iteration 93 : loss : 2.856239
Iteration 94 : loss : 3.019320
Iteration 95 : loss : 3.029822
Iteration 96 : loss : 2.992099
Iteration 97 : loss : 2.999933
Iteration 98 : loss : 2.954168
Finished Epoch 4/15,                       Train Accuracy: 0.6119258403778076,                       Train Loss: 3.0175329001076134
--------------------------------------------------
Starting Epoch 4/15
Iteration 99 : loss : 2.841551
Iteration 100 : loss : 2.771504
Iteration 101 : loss : 2.854610
Iteration 102 : loss : 2.812891
Iteration 103 : loss : 2.770995
Iteration 104 : loss : 2.886926
Iteration 105 : loss : 2.823127
Iteration 106 : loss : 2.818460
Iteration 107 : loss : 2.812998
Iteration 108 : loss : 2.809036
Iteration 109 : loss : 2.763312
Iteration 110 : loss : 2.835314
Iteration 111 : loss : 2.829523
Iteration 112 : loss : 2.891033
Iteration 113 : loss : 2.727668
Iteration 114 : loss : 2.798102
Iteration 115 : loss : 2.867342
Iteration 116 : loss : 2.923480
Iteration 117 : loss : 2.797524
Iteration 118 : loss : 2.803292
Iteration 119 : loss : 2.759501
Iteration 120 : loss : 2.842348
Iteration 121 : loss : 2.921981
Iteration 122 : loss : 2.801952
Iteration 123 : loss : 2.800702
Iteration 124 : loss : 2.788193
Iteration 125 : loss : 2.868041
Iteration 126 : loss : 2.839701
Iteration 127 : loss : 2.843836
Iteration 128 : loss : 2.800470
Iteration 129 : loss : 2.793338
Iteration 130 : loss : 2.779217
Iteration 131 : loss : 2.722068
Finished Epoch 5/15,                       Train Accuracy: 0.6871894598007202,                       Train Loss: 2.8204777498791946
--------------------------------------------------
Starting Epoch 5/15
Iteration 132 : loss : 2.702586
Iteration 133 : loss : 2.630519
Iteration 134 : loss : 2.668452
Iteration 135 : loss : 2.696172
Iteration 136 : loss : 2.654112
Iteration 137 : loss : 2.641966
Iteration 138 : loss : 2.623330
Iteration 139 : loss : 2.692627
Iteration 140 : loss : 2.680296
Iteration 141 : loss : 2.694258
Iteration 142 : loss : 2.646239
Iteration 143 : loss : 2.638840
Iteration 144 : loss : 2.754721
Iteration 145 : loss : 2.694647
Iteration 146 : loss : 2.601528
Iteration 147 : loss : 2.696087
Iteration 148 : loss : 2.607684
Iteration 149 : loss : 2.673660
Iteration 150 : loss : 2.650213
Iteration 151 : loss : 2.668999
Iteration 152 : loss : 2.749372
Iteration 153 : loss : 2.666540
Iteration 154 : loss : 2.675966
Iteration 155 : loss : 2.658384
Iteration 156 : loss : 2.675541
Iteration 157 : loss : 2.693173
Iteration 158 : loss : 2.652964
Iteration 159 : loss : 2.664416
Iteration 160 : loss : 2.651855
Iteration 161 : loss : 2.689344
Iteration 162 : loss : 2.731800
Iteration 163 : loss : 2.684166
Iteration 164 : loss : 2.682032
Finished Epoch 6/15,                       Train Accuracy: 0.7422130703926086,                       Train Loss: 2.672272125745077
--------------------------------------------------
Starting Epoch 6/15
Iteration 165 : loss : 2.591159
Iteration 166 : loss : 2.527467
Iteration 167 : loss : 2.493090
Iteration 168 : loss : 2.619983
Iteration 169 : loss : 2.538831
Iteration 170 : loss : 2.487034
Iteration 171 : loss : 2.489000
Iteration 172 : loss : 2.592993
Iteration 173 : loss : 2.581021
Iteration 174 : loss : 2.546256
Iteration 175 : loss : 2.589776
Iteration 176 : loss : 2.634579
Iteration 177 : loss : 2.543027
Iteration 178 : loss : 2.553674
Iteration 179 : loss : 2.580163
Iteration 180 : loss : 2.628478
Iteration 181 : loss : 2.524571
Iteration 182 : loss : 2.578507
Iteration 183 : loss : 2.549413
Iteration 184 : loss : 2.584752
Iteration 185 : loss : 2.585189
Iteration 186 : loss : 2.516959
Iteration 187 : loss : 2.566870
Iteration 188 : loss : 2.591249
Iteration 189 : loss : 2.544150
Iteration 190 : loss : 2.663813
Iteration 191 : loss : 2.592176
Iteration 192 : loss : 2.573573
Iteration 193 : loss : 2.641122
Iteration 194 : loss : 2.683065
Iteration 195 : loss : 2.508173
Iteration 196 : loss : 2.592572
Iteration 197 : loss : 2.698440
Finished Epoch 7/15,                       Train Accuracy: 0.7746939659118652,                       Train Loss: 2.5725530772740273
--------------------------------------------------
Starting Epoch 7/15
Iteration 198 : loss : 2.478467
Iteration 199 : loss : 2.476885
Iteration 200 : loss : 2.486665
Iteration 201 : loss : 2.438595
Iteration 202 : loss : 2.485557
Iteration 203 : loss : 2.431504
Iteration 204 : loss : 2.404297
Iteration 205 : loss : 2.487947
Iteration 206 : loss : 2.526331
Iteration 207 : loss : 2.414036
Iteration 208 : loss : 2.517633
Iteration 209 : loss : 2.445802
Iteration 210 : loss : 2.525990
Iteration 211 : loss : 2.441133
Iteration 212 : loss : 2.460788
Iteration 213 : loss : 2.475620
Iteration 214 : loss : 2.507210
Iteration 215 : loss : 2.455191
Iteration 216 : loss : 2.453860
Iteration 217 : loss : 2.433384
Iteration 218 : loss : 2.559953
Iteration 219 : loss : 2.524392
Iteration 220 : loss : 2.517192
Iteration 221 : loss : 2.481151
Iteration 222 : loss : 2.471640
Iteration 223 : loss : 2.506941
Iteration 224 : loss : 2.524864
Iteration 225 : loss : 2.545284
Iteration 226 : loss : 2.478048
Iteration 227 : loss : 2.513296
Iteration 228 : loss : 2.502380
Iteration 229 : loss : 2.522290
Iteration 230 : loss : 2.700088
Finished Epoch 8/15,                       Train Accuracy: 0.808992862701416,                       Train Loss: 2.4857415027176883
--------------------------------------------------
Starting Epoch 8/15
Iteration 231 : loss : 2.365736
Iteration 232 : loss : 2.398947
Iteration 233 : loss : 2.359895
Iteration 234 : loss : 2.395745
Iteration 235 : loss : 2.391648
Iteration 236 : loss : 2.411507
Iteration 237 : loss : 2.358137
Iteration 238 : loss : 2.324900
Iteration 239 : loss : 2.433409
Iteration 240 : loss : 2.432328
Iteration 241 : loss : 2.416343
Iteration 242 : loss : 2.314684
Iteration 243 : loss : 2.433373
Iteration 244 : loss : 2.344056
Iteration 245 : loss : 2.443080
Iteration 246 : loss : 2.425413
Iteration 247 : loss : 2.422222
Iteration 248 : loss : 2.381347
Iteration 249 : loss : 2.382458
Iteration 250 : loss : 2.404347
Iteration 251 : loss : 2.430716
Iteration 252 : loss : 2.429729
Iteration 253 : loss : 2.428127
Iteration 254 : loss : 2.386074
Iteration 255 : loss : 2.350979
Iteration 256 : loss : 2.394823
Iteration 257 : loss : 2.403545
Iteration 258 : loss : 2.394484
Iteration 259 : loss : 2.405988
Iteration 260 : loss : 2.403007
Iteration 261 : loss : 2.385519
Iteration 262 : loss : 2.454449
Iteration 263 : loss : 2.444988
Finished Epoch 9/15,                       Train Accuracy: 0.8440188765525818,                       Train Loss: 2.397436672811031
--------------------------------------------------
Starting Epoch 9/15
Iteration 264 : loss : 2.296093
Iteration 265 : loss : 2.299525
Iteration 266 : loss : 2.291330
Iteration 267 : loss : 2.304564
Iteration 268 : loss : 2.321255
Iteration 269 : loss : 2.318819
Iteration 270 : loss : 2.370740
Iteration 271 : loss : 2.266915
Iteration 272 : loss : 2.279693
Iteration 273 : loss : 2.335851
Iteration 274 : loss : 2.282996
Iteration 275 : loss : 2.325722
Iteration 276 : loss : 2.304482
Iteration 277 : loss : 2.354890
Iteration 278 : loss : 2.248076
Iteration 279 : loss : 2.339025
Iteration 280 : loss : 2.325438
Iteration 281 : loss : 2.276196
Iteration 282 : loss : 2.337973
Iteration 283 : loss : 2.309934
Iteration 284 : loss : 2.307815
Iteration 285 : loss : 2.418645
Iteration 286 : loss : 2.313470
Iteration 287 : loss : 2.320545
Iteration 288 : loss : 2.291762
Iteration 289 : loss : 2.309932
Iteration 290 : loss : 2.371398
Iteration 291 : loss : 2.365536
Iteration 292 : loss : 2.375960
Iteration 293 : loss : 2.343163
Iteration 294 : loss : 2.326016
Iteration 295 : loss : 2.343571
Iteration 296 : loss : 2.592216
Finished Epoch 10/15,                       Train Accuracy: 0.8720155358314514,                       Train Loss: 2.3231048019939937
--------------------------------------------------
Starting Epoch 10/15
Iteration 297 : loss : 2.230482
Iteration 298 : loss : 2.280777
Iteration 299 : loss : 2.297596
Iteration 300 : loss : 2.262061
Iteration 301 : loss : 2.209738
Iteration 302 : loss : 2.294274
Iteration 303 : loss : 2.301529
Iteration 304 : loss : 2.286197
Iteration 305 : loss : 2.274199
Iteration 306 : loss : 2.225830
Iteration 307 : loss : 2.316646
Iteration 308 : loss : 2.297354
Iteration 309 : loss : 2.267099
Iteration 310 : loss : 2.231823
Iteration 311 : loss : 2.263627
Iteration 312 : loss : 2.269348
Iteration 313 : loss : 2.313396
Iteration 314 : loss : 2.283332
Iteration 315 : loss : 2.276654
Iteration 316 : loss : 2.303193
Iteration 317 : loss : 2.275609
Iteration 318 : loss : 2.215778
Iteration 319 : loss : 2.347235
Iteration 320 : loss : 2.293612
Iteration 321 : loss : 2.326951
Iteration 322 : loss : 2.266491
Iteration 323 : loss : 2.278826
Iteration 324 : loss : 2.348846
Iteration 325 : loss : 2.333960
Iteration 326 : loss : 2.247190
Iteration 327 : loss : 2.225325
Iteration 328 : loss : 2.268112
Iteration 329 : loss : 2.465009
Finished Epoch 11/15,                       Train Accuracy: 0.891043484210968,                       Train Loss: 2.279867399072607
--------------------------------------------------
Starting Epoch 11/15
Iteration 330 : loss : 2.225702
Iteration 331 : loss : 2.163680
Iteration 332 : loss : 2.188784
Iteration 333 : loss : 2.271472
Iteration 334 : loss : 2.163154
Iteration 335 : loss : 2.205849
Iteration 336 : loss : 2.276423
Iteration 337 : loss : 2.206152
Iteration 338 : loss : 2.204098
Iteration 339 : loss : 2.292159
Iteration 340 : loss : 2.209010
Iteration 341 : loss : 2.174216
Iteration 342 : loss : 2.191318
Iteration 343 : loss : 2.204090
Iteration 344 : loss : 2.263669
Iteration 345 : loss : 2.256652
Iteration 346 : loss : 2.249973
Iteration 347 : loss : 2.167110
Iteration 348 : loss : 2.163773
Iteration 349 : loss : 2.227514
Iteration 350 : loss : 2.194266
Iteration 351 : loss : 2.264020
Iteration 352 : loss : 2.253279
Iteration 353 : loss : 2.204522
Iteration 354 : loss : 2.249427
Iteration 355 : loss : 2.281720
Iteration 356 : loss : 2.194287
Iteration 357 : loss : 2.186222
Iteration 358 : loss : 2.196010
Iteration 359 : loss : 2.176689
Iteration 360 : loss : 2.259109
Iteration 361 : loss : 2.225797
Iteration 362 : loss : 2.223134
Finished Epoch 12/15,                       Train Accuracy: 0.9078899621963501,                       Train Loss: 2.2184756147458384
--------------------------------------------------
Starting Epoch 12/15
Iteration 363 : loss : 2.119904
Iteration 364 : loss : 2.172505
Iteration 365 : loss : 2.174129
Iteration 366 : loss : 2.121207
Iteration 367 : loss : 2.158583
Iteration 368 : loss : 2.196798
Iteration 369 : loss : 2.191302
Iteration 370 : loss : 2.195043
Iteration 371 : loss : 2.152285
Iteration 372 : loss : 2.178216
Iteration 373 : loss : 2.141859
Iteration 374 : loss : 2.138060
Iteration 375 : loss : 2.133405
Iteration 376 : loss : 2.174684
Iteration 377 : loss : 2.199915
Iteration 378 : loss : 2.177718
Iteration 379 : loss : 2.156135
Iteration 380 : loss : 2.155031
Iteration 381 : loss : 2.133958
Iteration 382 : loss : 2.212269
Iteration 383 : loss : 2.152515
Iteration 384 : loss : 2.114642
Iteration 385 : loss : 2.207578
Iteration 386 : loss : 2.146096
Iteration 387 : loss : 2.181653
Iteration 388 : loss : 2.235497
Iteration 389 : loss : 2.171433
Iteration 390 : loss : 2.172559
Iteration 391 : loss : 2.147651
Iteration 392 : loss : 2.232724
Iteration 393 : loss : 2.165101
Iteration 394 : loss : 2.192909
Iteration 395 : loss : 2.269298
Finished Epoch 13/15,                       Train Accuracy: 0.9265543818473816,                       Train Loss: 2.1695732831983854
--------------------------------------------------
Starting Epoch 13/15
Iteration 396 : loss : 2.092790
Iteration 397 : loss : 2.085033
Iteration 398 : loss : 2.142741
Iteration 399 : loss : 2.142666
Iteration 400 : loss : 2.144032
Iteration 401 : loss : 2.102820
Iteration 402 : loss : 2.091107
Iteration 403 : loss : 2.191706
Iteration 404 : loss : 2.146792
Iteration 405 : loss : 2.149953
Iteration 406 : loss : 2.111970
Iteration 407 : loss : 2.101362
Iteration 408 : loss : 2.128466
Iteration 409 : loss : 2.100520
Iteration 410 : loss : 2.138851
Iteration 411 : loss : 2.143907
Iteration 412 : loss : 2.122490
Iteration 413 : loss : 2.213918
Iteration 414 : loss : 2.138936
Iteration 415 : loss : 2.148148
Iteration 416 : loss : 2.157260
Iteration 417 : loss : 2.122314
Iteration 418 : loss : 2.165646
Iteration 419 : loss : 2.112697
Iteration 420 : loss : 2.183242
Iteration 421 : loss : 2.164623
Iteration 422 : loss : 2.150435
Iteration 423 : loss : 2.140802
Iteration 424 : loss : 2.106616
Iteration 425 : loss : 2.184005
Iteration 426 : loss : 2.147218
Iteration 427 : loss : 2.131666
Iteration 428 : loss : 2.176394
Finished Epoch 14/15,                       Train Accuracy: 0.9322506189346313,                       Train Loss: 2.1379249566628014
--------------------------------------------------
Starting Epoch 14/15
Iteration 429 : loss : 2.044778
Iteration 430 : loss : 2.088977
Iteration 431 : loss : 2.109549
Iteration 432 : loss : 2.062176
Iteration 433 : loss : 2.083922
Iteration 434 : loss : 2.078084
Iteration 435 : loss : 2.103777
Iteration 436 : loss : 2.090199
Iteration 437 : loss : 2.114698
Iteration 438 : loss : 2.095364
Iteration 439 : loss : 2.049667
Iteration 440 : loss : 2.097964
Iteration 441 : loss : 2.089108
Iteration 442 : loss : 2.055189
Iteration 443 : loss : 2.111873
Iteration 444 : loss : 2.087023
Iteration 445 : loss : 2.082823
Iteration 446 : loss : 2.078411
Iteration 447 : loss : 2.058818
Iteration 448 : loss : 2.102298
Iteration 449 : loss : 2.113330
Iteration 450 : loss : 2.063410
Iteration 451 : loss : 2.145808
Iteration 452 : loss : 2.132754
Iteration 453 : loss : 2.097678
Iteration 454 : loss : 2.124837
Iteration 455 : loss : 2.108807
Iteration 456 : loss : 2.146922
Iteration 457 : loss : 2.107039
Iteration 458 : loss : 2.133914
Iteration 459 : loss : 2.131000
Iteration 460 : loss : 2.096883
Iteration 461 : loss : 2.233565
Finished Epoch 15/15,                       Train Accuracy: 0.9435219764709473,                       Train Loss: 2.0974515360234767
--------------------------------------------------
Starting Epoch 15/15
Iteration 462 : loss : 2.079148
Iteration 463 : loss : 2.039547
Iteration 464 : loss : 2.030318
Iteration 465 : loss : 2.093903
Iteration 466 : loss : 2.080018
Iteration 467 : loss : 2.058633
Iteration 468 : loss : 2.061534
Iteration 469 : loss : 2.075419
Iteration 470 : loss : 2.100926
Iteration 471 : loss : 2.113619
Iteration 472 : loss : 2.078115
Iteration 473 : loss : 2.066583
Iteration 474 : loss : 2.075879
Iteration 475 : loss : 2.109291
Iteration 476 : loss : 2.058104
Iteration 477 : loss : 2.060534
Iteration 478 : loss : 2.065889
Iteration 479 : loss : 2.041566
Iteration 480 : loss : 2.041856
Iteration 481 : loss : 2.024640
Iteration 482 : loss : 2.037955
Iteration 483 : loss : 2.031998
Iteration 484 : loss : 2.075544
Iteration 485 : loss : 2.070177
Iteration 486 : loss : 2.119470
Iteration 487 : loss : 2.068634
Iteration 488 : loss : 2.111123
Iteration 489 : loss : 2.077806
Iteration 490 : loss : 2.123092
Iteration 491 : loss : 2.069102
Iteration 492 : loss : 2.067459
Iteration 493 : loss : 2.085767
Iteration 494 : loss : 2.196035
Finished Epoch 16/15,                       Train Accuracy: 0.9493394494056702,                       Train Loss: 2.072565713805468
--------------------------------------------------
